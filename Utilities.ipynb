{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmatrella/BirdsSound/blob/main/Utilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd \"/content/drive/MyDrive/Marino_Matrella\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6z6Xx4D5aLR",
        "outputId": "cb3b8bed-9f2e-4766-dcba-a1b721baac28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/.shortcut-targets-by-id/1pfBa0fnatsy0qYLtZ2wpGwzSR-zOPP2W/CIDL project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U tensorflow_addons\n",
        "! pip install -q \"tqdm>=4.36.1\"\n",
        "!pip install spec_augment\n",
        "!pip install tf-nightly"
      ],
      "metadata": {
        "id": "vQl1oXWWnueW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76988e38-1462-4680-e2a7-901a7c3ab427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.20.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spec_augment\n",
            "  Downloading spec_augment-0.0.3-py3-none-any.whl (4.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from spec_augment) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->spec_augment) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->spec_augment) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->spec_augment) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->spec_augment) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->spec_augment) (3.2.2)\n",
            "Installing collected packages: spec_augment\n",
            "Successfully installed spec_augment-0.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.14.0.dev20230619-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.6.3)\n",
            "Collecting flatbuffers>=23.5.26 (from tf-nightly)\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.8.0)\n",
            "Collecting keras-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading keras_nightly-2.14.0.dev2023061907-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.16.0)\n",
            "Collecting tb-nightly~=2.14.0.a (from tf-nightly)\n",
            "  Downloading tb_nightly-2.14.0a20230618-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (2.3.0)\n",
            "Collecting tf-estimator-nightly~=2.14.0.dev (from tf-nightly)\n",
            "  Downloading tf_estimator_nightly-2.14.0.dev2023061908-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.0/441.0 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tf-nightly) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly~=2.14.0.a->tf-nightly) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.14.0.a->tf-nightly) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tf-estimator-nightly, keras-nightly, tb-nightly, tf-nightly\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "Successfully installed flatbuffers-23.5.26 keras-nightly-2.14.0.dev2023061907 tb-nightly-2.14.0a20230618 tf-estimator-nightly-2.14.0.dev2023061908 tf-nightly-2.14.0.dev20230619\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#import tensorflow_addons as tfa\n",
        "from keras import regularizers\n",
        "from tensorflow.keras import layers, models, metrics\n",
        "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
        "from tensorflow.keras.utils import to_categorical, image_dataset_from_directory\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow import keras\n",
        "from spec_augment import SpecAugment\n",
        "import cv2 as cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "sns.set_theme(style='ticks')"
      ],
      "metadata": {
        "id": "kJbZgFoQ5DSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('tensor version is ', tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5GBv_DA2yAd",
        "outputId": "18928ac9-8a9c-499b-bc27-0329066150ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor version is  2.14.0-dev20230613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDyIz2e84xyQ"
      },
      "outputs": [],
      "source": [
        "def compute_class_weights(train_path):\n",
        "  labels = os.listdir(train_path)\n",
        "  classes = []\n",
        "  for label in labels:\n",
        "    n = len(os.listdir(os.path.join(train_path,label)))\n",
        "    p = [label] * n\n",
        "    classes = [y for x in [classes, p] for y in x]\n",
        "\n",
        "  from sklearn.utils.class_weight import compute_class_weight\n",
        "  class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(classes), y= np.array(classes))\n",
        "  class_weights={k: v for k, v in enumerate(class_weights)}\n",
        "\n",
        "  return class_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed ():\n",
        "  '''\n",
        "  set_seed is used to obtain reproducible results using keras during the development phase\n",
        "  '''\n",
        "  seed = 24\n",
        "  # The below is necessary for reproducible results of certain Python hash-based operations.\n",
        "  os.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
        "  # The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
        "  np.random.seed(seed)\n",
        "  # The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
        "  random.seed(seed)\n",
        "  # The below tf.random.set_seed will make random number generation in TensorFlow have a well-defined initial state.\n",
        "  tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "jZwN5Xcx4zTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed()"
      ],
      "metadata": {
        "id": "kSX2MC1dUyMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model (model, optimizer='adam', learning_rate = 0.0001):\n",
        "  '''\n",
        "  compile_model is used to compile the current model\n",
        "  :param model: model to compile\n",
        "  :param optimizer: optimizer to be used\n",
        "  :param learning_rate: learning rate parameter for the optimizer\n",
        "  '''\n",
        "  if optimizer == 'adam':\n",
        "    model.compile(loss = \"categorical_crossentropy\",\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  metrics = [\n",
        "                              \"accuracy\",\n",
        "                              F1Score(average=\"weighted\")\n",
        "                            ])\n",
        "\n",
        "  elif optimizer == 'rmsprop':\n",
        "    model.compile(loss = \"categorical_crossentropy\",\n",
        "                  optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
        "                  metrics = [\n",
        "                              \"accuracy\",\n",
        "                              F1Score(average=\"weighted\")\n",
        "                            ])\n",
        "  elif optimizer == 'sgd':\n",
        "    model.compile(loss = \"categorical_crossentropy\",\n",
        "                  optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, weight_decay=0.001),\n",
        "                  metrics = [\n",
        "                              \"accuracy\",\n",
        "                              F1Score(average=\"weighted\")\n",
        "                            ])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_model (model, model_name, train_dataset, validation_dataset, MODELS_FOLDER, class_weights=None, epochs=50, patience=5, monitor='val_loss'):    #class_weights=None\n",
        "  '''\n",
        "  run_model is used to run the current mode\n",
        "  :param model: model to run\n",
        "  :param model_name: name given to save the model\n",
        "  :param epochs: how many epochs to do\n",
        "  :param patience: patience value for Early Stopping\n",
        "  :param monitor: what to monitor for Early Stopping and Model Checkpoint\n",
        "  '''\n",
        "  if not os.path.exists(MODELS_FOLDER):\n",
        "    os.makedirs(MODELS_FOLDER)\n",
        "\n",
        "  #save path for the models\n",
        "  checkpoint_filepath = os.path.join(MODELS_FOLDER, model_name + '.h5')\n",
        "\n",
        "  callbacks_list = [\n",
        "                  keras.callbacks.EarlyStopping(\n",
        "                      monitor=monitor,\n",
        "                      patience=patience,\n",
        "                      verbose=1,\n",
        "                      mode='min'\n",
        "                  ),\n",
        "                  keras.callbacks.ModelCheckpoint(\n",
        "                      filepath = checkpoint_filepath,\n",
        "                      monitor=monitor,\n",
        "                      verbose=1,\n",
        "                      save_best_only=True\n",
        "                  ),\n",
        "                  keras.callbacks.ReduceLROnPlateau(\n",
        "                      monitor=monitor,\n",
        "                      factor=0.1,\n",
        "                      patience=3\n",
        "                  ),\n",
        "                  # tfa.callbacks.TQDMProgressBar()\n",
        "                  ]\n",
        "\n",
        "\n",
        "  history = model.fit(train_dataset,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_dataset,\n",
        "                    callbacks=callbacks_list,\n",
        "                    class_weight=class_weights\n",
        "                    )\n",
        "\n",
        "  history = pd.DataFrame(history.history)\n",
        "  history.to_csv(os.path.join(MODELS_FOLDER, model_name + '_history.csv'), index=False)\n",
        "\n",
        "  return history\n",
        "\n",
        "\n",
        "def plot_model_performance(history=None, path=None, axis=1):\n",
        "  '''\n",
        "  show training and validation performances, plotting the performances during the training phase\n",
        "    :param history: object in which are recorded all the events\n",
        "    :path current path of the hystory saved somewhere\n",
        "    :axis vertical (1) or horizontal (0) plot\n",
        "  '''\n",
        "\n",
        "  if path is not None:\n",
        "    history = pd.read_csv(path + '_history.csv')\n",
        "\n",
        "  s = pd.Index(np.arange(history.shape[0])+1)\n",
        "  accuracy_results = history[['accuracy', 'val_accuracy']]\n",
        "  accuracy_results = accuracy_results.set_index([s])\n",
        "\n",
        "  loss_results = history[['loss', 'val_loss']]\n",
        "  loss_results = loss_results.set_index([s])\n",
        "  val_loss_min = loss_results[['val_loss']].idxmin()\n",
        "  val_loss_min=val_loss_min.values[0]\n",
        "\n",
        "  f1_results = history[['f1_score', 'val_f1_score']]\n",
        "  f1_results = f1_results.set_index([s])\n",
        "\n",
        "  if axis == 1:\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(5,10))\n",
        "  else:\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,4))\n",
        "\n",
        "  sns.lineplot(data = accuracy_results, ax=ax1)\n",
        "  ax1.title.set_text('Training and validation accuracy')\n",
        "  ax1.set_xlabel('Epochs')\n",
        "  ax1.set_ylabel('Accuracy')\n",
        "  ax1.axvline(val_loss_min, color='lightgrey')\n",
        "  ax1.grid()\n",
        "\n",
        "  print()\n",
        "\n",
        "  sns.lineplot(data = loss_results, ax=ax2)\n",
        "  ax2.title.set_text('Training and validation loss')\n",
        "  ax2.set_xlabel('Epochs')\n",
        "  ax2.set_ylabel('Loss')\n",
        "  ax2.axvline(val_loss_min, color='lightgrey')\n",
        "  ax2.grid()\n",
        "\n",
        "  print()\n",
        "\n",
        "  sns.lineplot(data = f1_results, ax=ax3)\n",
        "  ax3.title.set_text('Training and validation f1')\n",
        "  ax3.set_xlabel('Epochs')\n",
        "  ax3.set_ylabel('F1')\n",
        "  ax3.axvline(val_loss_min, color='lightgrey')\n",
        "  ax3.grid()\n",
        "\n",
        "\n",
        "def evaluate_model(model):  ###ok\n",
        "\n",
        "  y_true = tf.concat([labels_batch for data_batch, labels_batch in test_set], axis = 0)\n",
        "  y_true_cat = np.argmax(y_true, -1)\n",
        "\n",
        "  pred_Y = model.predict(test_set, verbose = True)\n",
        "  pred_Y_cat = np.argmax(pred_Y, -1)\n",
        "\n",
        "  # print metrics\n",
        "  results=model.evaluate(test_set)\n",
        "  print()\n",
        "  print(f\"Test loss: {results[0]:.3f}\")\n",
        "  print(f\"Test accuracy: {results[1]:.3f}\")\n",
        "  print(f\"Test f1: {results[2]:.3f}\")\n",
        "  print()\n",
        "\n",
        "  accuracy = accuracy_score(y_true_cat, pred_Y_cat)\n",
        "  print(\"Accuracy on test data: %.2f %%\" % (accuracy * 100))\n",
        "  f1 = f1_score(y_true_cat, pred_Y_cat, average='weighted')\n",
        "  print(\"F1-Score on test data: %.2f %%\" % (f1 * 100))\n",
        "  print()\n",
        "  class_label = np.array(test_set.class_names)\n",
        "  print(classification_report(class_label[y_true_cat], class_label[pred_Y_cat]))"
      ],
      "metadata": {
        "id": "AOE0roRZmn_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spec_augment = keras.Sequential([\n",
        "\n",
        "#  LB usato\n",
        "  SpecAugment(freq_mask_param=27,\n",
        "                           time_mask_param=100,\n",
        "                           n_freq_mask=1,\n",
        "                           n_time_mask=1\n",
        "                           )\n",
        "  #LD\n",
        "    # SpecAugment(freq_mask_param=27,\n",
        "    #                        time_mask_param=100,\n",
        "    #                        n_freq_mask=2,\n",
        "    #                        n_time_mask=2,\n",
        "    #                        mask_value=-100)\n",
        "  #SM usato\n",
        "  # SpecAugment(freq_mask_param=15,\n",
        "  #                          time_mask_param=70,\n",
        "  #                          n_freq_mask=2,\n",
        "  #                          n_time_mask=2,\n",
        "  #                          mask_value=-100)\n",
        "  #SS\n",
        "  #  SpecAugment(freq_mask_param=27,\n",
        "  #                          time_mask_param=70,\n",
        "  #                          n_freq_mask=2,\n",
        "  #                          n_time_mask=2,\n",
        "  #                          mask_value=-100)\n",
        "])\n"
      ],
      "metadata": {
        "id": "jNFsQEiVSkR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomContrast(factor=0.15),\n",
        "  layers.RandomZoom(0.1, fill_mode=\"constant\", fill_value=0.0),\n",
        "  layers.RandomRotation(factor=1, fill_mode=\"constant\", fill_value=0.0),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "c8uNTiLQV7fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_labels():\n",
        "  return np.array(test_set.class_names)"
      ],
      "metadata": {
        "id": "M60DjkCKazy8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}